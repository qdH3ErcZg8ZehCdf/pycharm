{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: telegram in /home/g/.local/lib/python3.8/site-packages (0.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tornado in /usr/lib/python3.8/site-packages (6.0.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-telegram-bot in /home/g/.local/lib/python3.8/site-packages (12.7)\n",
      "Requirement already satisfied: decorator>=4.4.0 in /usr/lib/python3.8/site-packages (from python-telegram-bot) (4.4.2)\n",
      "Requirement already satisfied: tornado>=5.1 in /usr/lib/python3.8/site-packages (from python-telegram-bot) (6.0.4)\n",
      "Requirement already satisfied: future>=0.16.0 in /usr/lib/python3.8/site-packages (from python-telegram-bot) (0.18.2)\n",
      "Requirement already satisfied: cryptography in /usr/lib/python3.8/site-packages (from python-telegram-bot) (2.9.2)\n",
      "Requirement already satisfied: certifi in /home/g/.local/lib/python3.8/site-packages (from python-telegram-bot) (2020.4.5.1)\n",
      "Requirement already satisfied: six>=1.4.1 in /usr/lib/python3.8/site-packages (from cryptography->python-telegram-bot) (1.15.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/lib/python3.8/site-packages (from cryptography->python-telegram-bot) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /usr/lib/python3.8/site-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot) (2.20)\n"
     ]
    }
   ],
   "source": [
    "#  !apt-get update\n",
    "# !apt-get upgrade\n",
    "# pip install sklearn\n",
    "!pip install telegram\n",
    "!pip install tornado\n",
    "!pip install python-telegram-bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT_CONFIG = {\n",
    "    'intents': {\n",
    "        'hello': {\n",
    "            'examples': ['Йо', 'Хай', 'Дарова', 'Привет', 'Добрый день', 'Здравствуй', 'Шалом'],\n",
    "            'responses': ['Йо', 'Хай', 'Дарова', 'Привет', 'Добрый день', 'Здравствуй', 'Шалом']\n",
    "        },\n",
    "        'goodbye': {\n",
    "            'examples': ['Счастливо', 'Пока', 'Всего доброго', 'До свидания', 'До встречи', 'Давай', 'Бывай'],\n",
    "            'responses': ['Счастливо', 'Пока', 'Всего доброго', 'До свидания', 'До встречи', 'Давай', 'Бывай'],\n",
    "        },\n",
    "        'thanks': {\n",
    "            'examples': ['Спасибо', 'Спасибо большое', 'Сенкс', 'Благодарю', 'Мерси', 'Спс'],\n",
    "            'responses': ['Вам спасибо!', 'Не за что', 'Пожалуйста', 'На здоровье', 'Обращайтесь']\n",
    "        },\n",
    "        'whatcanyoudo': {\n",
    "            'examples': ['Что ты умеешь?', 'Расскажи что умеешь', 'Помощь', 'Справка', 'Возможности'],\n",
    "            'responses': ['Я могу отвечать на вопросы. Просто напиши :)']\n",
    "        },\n",
    "        'name': {\n",
    "            'examples': ['Как тебя зовут?', 'Твое имя?', 'Как к тебе обращаться?', 'Как тебя назвали?', 'Имя', 'Как зовут'],\n",
    "            'responses': ['Меня зовут бот. Просто бот.']\n",
    "        },\n",
    "        'weather': {\n",
    "            'examples': ['Какая погода в Москве?', 'Какая погода?', 'Прогноз погоды?', 'Что с погодой', 'Как на улице?'],\n",
    "            'responses': ['Погода так себе...']\n",
    "        },\n",
    "        'mood': {\n",
    "            'examples': ['Как себя чувствуешь', 'Как настроение', 'Ты как', 'Как ты', 'Как ты там', 'Все нормально?', 'Как дела'],\n",
    "            'responses': ['Нормально', 'Не очень', 'Отлично', 'Бывает и лучше', 'Нормуль', 'Всё ОК']\n",
    "        },\n",
    "        'advice': {\n",
    "            'examples': ['Дай совет', 'Нужен совет', 'Как поступить', 'Что мне делать', 'Что делать', 'Посоветуй', 'Подскажи', 'Как думаешь'],\n",
    "            'responses': ['Не бойся принимать решение', 'Осознай сомнения и проработай', 'Не тормози', 'Нормально делай - нормально будет']\n",
    "        },\n",
    "        'wishes': {\n",
    "            'examples': ['Доброе утро', 'Хорошего дня', 'Как поступить', 'Что мне делать', 'Что делать', 'Посоветуй', 'Подскажи', 'Как думаешь'],\n",
    "            'responses': ['Спасибо', 'Взаимно', 'И тебе']\n",
    "        },\n",
    "        'ask': {\n",
    "            'examples': ['Почему', 'А чего так', 'Как так', 'Зачем'],\n",
    "            'responses': ['Если б знал', 'Не знаю', 'Да фиг его знает', 'Разное бывает']\n",
    "        },\n",
    "        'complain': {\n",
    "            'examples': ['Я устал', 'Устал', 'Мне плохо', 'Заколебался', 'Все достало', 'Нет сил', 'Ну и денек', 'Все плохо'],\n",
    "            'responses': ['Возьми себя в руки', 'Бывает, не парься', 'Сделай паузу и глубоко вдохни', 'Не принимай близко к сердцу', 'Не бери в голову']\n",
    "        },\n",
    "    },\n",
    "    'failure_phrases': [\n",
    "        'Извините, я вас не понял',\n",
    "        'Чиво?'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_TRESHOLD = 0.2\n",
    "GENERATIVE_TRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-12 17:33:06--  https://raw.githubusercontent.com/Koziev/NLP_Datasets/master/Conversations/Data/ru.conversations.txt\n",
      "Загружен сертификат CA «/etc/ssl/certs/ca-certificates.crt»\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 151.101.112.133\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 9718314 (9,3M) [text/plain]\n",
      "Сохранение в: «ru.conversations.txt»\n",
      "\n",
      "ru.conversations.tx   9%[>                   ] 935,57K  23,1KB/s    за 4m 25s  \n",
      "\n",
      "2020-07-12 17:37:33 (3,53 KB/s) - Соединение закрыто, позиция 958023. Повтор.\n",
      "\n",
      "--2020-07-12 17:37:34--  (попытка: 2)  https://raw.githubusercontent.com/Koziev/NLP_Datasets/master/Conversations/Data/ru.conversations.txt\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 206 Partial Content\n",
      "Длина: 9718314 (9,3M), 8760291 (8,4M) осталось [text/plain]\n",
      "Сохранение в: «ru.conversations.txt»\n",
      "\n",
      "ru.conversations.tx 100%[+==================>]   9,27M   267KB/s    за 2m 38s  \n",
      "\n",
      "2020-07-12 17:40:15 (54,1 KB/s) - «ru.conversations.txt» сохранён [9718314/9718314]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Загрузка дата сета\n",
    "!wget https://raw.githubusercontent.com/Koziev/NLP_Datasets/master/Conversations/Data/ru.conversations.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dialogues.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-45f3a90ba18d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dialogues.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdialogues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dialogues.txt'"
     ]
    }
   ],
   "source": [
    "with open('dialogues.txt') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "dialogues = []\n",
    "\n",
    "for dialogue in data.split('\\n\\n'):\n",
    "    \n",
    "    replicas = []\n",
    "    for replica in dialogue.split('\\n')[:2]:\n",
    "        replica = replica[2:].lower()\n",
    "        replicas.append(replica)\n",
    "        \n",
    "    if len(replicas) == 2 and len(replicas[0]) > 1 and len(replicas[1]) > 0:\n",
    "        dialogues.append(replicas)\n",
    "        \n",
    "GENERATIVE_DIALOGUES = dialogues[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_text = []\n",
    "y = []\n",
    "\n",
    "for intent, value in BOT_CONFIG['intents'].items():\n",
    "    for example in value['examples']:\n",
    "        X_text.append(example)\n",
    "        y.append(intent)\n",
    "        \n",
    "VECTORIZER = CountVectorizer()\n",
    "X = VECTORIZER.fit_transform(X_text)\n",
    "\n",
    "CLF = LogisticRegression()\n",
    "CLF.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent(text):\n",
    "    probas = CLF.predict_proba(VECTORIZER.transform([text]))\n",
    "    max_proba = max(probas[0])\n",
    "    if max_proba >= CLASSIFIER_TRESHOLD:\n",
    "        index = list(probas[0]).index(max_proba)\n",
    "        return CLF.classes_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(get_intent('привет'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "def get_answer_by_generative_model(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    for question, answer in GENERATIVE_DIALOGUES:\n",
    "        if abs(len(text) - len(question)) / len(question) < 1 - GENERATIVE_TRESHOLD:\n",
    "            dist = edit_distance(text, question)\n",
    "            l = len(question)\n",
    "            similarity = 1 - dist / l\n",
    "            if similarity > GENERATIVE_TRESHOLD:\n",
    "                return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_response_by_intent(intent):\n",
    "    responses = BOT_CONFIG['intents'][intent]['responses']\n",
    "    return random.choice(responses)\n",
    "\n",
    "def get_failure_phrase():\n",
    "    phrases = BOT_CONFIG['failure_phrases']\n",
    "    return random.choice(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'requests': 0,\n",
    "    'byscript': 0,\n",
    "    'bygenerative': 0,\n",
    "    'stub': 0\n",
    "}\n",
    "\n",
    "def generate_answer(text):\n",
    "    stats['requests'] += 1\n",
    "    \n",
    "    # NLU\n",
    "    intent = get_intent(text)\n",
    "    \n",
    "    # Make answer\n",
    "    \n",
    "    # by script\n",
    "    if intent:\n",
    "        stats['byscript'] += 1\n",
    "        response = get_response_by_intent(intent)\n",
    "        return response\n",
    "    \n",
    "    # use generative model\n",
    "    answer = get_answer_by_generative_model(text)\n",
    "    if answer:\n",
    "        stats['bygenerative'] += 1\n",
    "        return answer\n",
    "    \n",
    "    stats['stub'] += 1\n",
    "    failure_phrase = get_failure_phrase()\n",
    "    return failure_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     text = input('Введите вопрос: ')\n",
    "#    answer = generate_answer(text)\n",
    "#    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-telegram-bot\n",
      "  Downloading python_telegram_bot-12.7-py2.py3-none-any.whl (375 kB)\n",
      "\u001b[K     |████████████████████████████████| 375 kB 297 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tornado>=5.1 in /usr/lib/python3.8/site-packages (from python-telegram-bot) (6.0.4)\n",
      "Requirement already satisfied: future>=0.16.0 in /usr/lib/python3.8/site-packages (from python-telegram-bot) (0.18.2)\n",
      "Requirement already satisfied: cryptography in /usr/lib/python3.8/site-packages (from python-telegram-bot) (2.9.2)\n",
      "Requirement already satisfied: decorator>=4.4.0 in /usr/lib/python3.8/site-packages (from python-telegram-bot) (4.4.2)\n",
      "Requirement already satisfied: certifi in /home/g/.local/lib/python3.8/site-packages (from python-telegram-bot) (2020.4.5.1)\n",
      "Requirement already satisfied: six>=1.4.1 in /usr/lib/python3.8/site-packages (from cryptography->python-telegram-bot) (1.15.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/lib/python3.8/site-packages (from cryptography->python-telegram-bot) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /usr/lib/python3.8/site-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot) (2.20)\n",
      "Installing collected packages: python-telegram-bot\n",
      "Successfully installed python-telegram-bot-12.7\n"
     ]
    }
   ],
   "source": [
    "#! pip install python-telegram-bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код бота\n",
    "\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
    "\n",
    "TOKEN = \"0000000000:11111111111111111111111111111111111\"\n",
    "\n",
    "def start(update, context):\n",
    "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
    "    update.message.reply_text('Hi!')\n",
    "\n",
    "def help(update, context):\n",
    "    \"\"\"Send a message when the command /help is issued.\"\"\"\n",
    "    update.message.reply_text('Help!')\n",
    "\n",
    "# def echo(update, context):\n",
    "#     \"\"\"Echo the user message.\"\"\"\n",
    "#     update.message.reply_text(update.message.text)\n",
    "\n",
    "def text(update, context):\n",
    "    \"\"\"Ответ уже от движка\"\"\"\n",
    "    answer = generate_answer(update.message.text)\n",
    "    print(update.message.text, '->', answer)\n",
    "    print(stats)\n",
    "    print()\n",
    "    update.message.reply_text(answer)\n",
    "\n",
    "def error(update, context):\n",
    "    update.message.reply_text('Я работаю только с текстом')\n",
    "\n",
    "def main():\n",
    "    # pip install pysocks\n",
    "    updater = Updater(TOKEN, request_kwargs={'proxy_url': 'socks5://5.133.194.171:12951'}, use_context=True)\n",
    "    # updater = Updater(TOKEN, use_context=True)\n",
    "    \n",
    "    dp = updater.dispatcher\n",
    "    dp.add_handler(CommandHandler(\"start\", start))\n",
    "    dp.add_handler(CommandHandler(\"help\", help))\n",
    "#     dp.add_handler(MessageHandler(Filters.text, echo))\n",
    "    dp.add_handler(MessageHandler(Filters.text, text))\n",
    "    dp.add_error_handler(error)\n",
    "    updater.start_polling()\n",
    "    updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет -> Добрый день\n",
      "{'requests': 1, 'byscript': 1, 'bygenerative': 0, 'stub': 0}\n",
      "\n",
      "Сколько тебе годиков? -> Извините, я вас не понял\n",
      "{'requests': 2, 'byscript': 1, 'bygenerative': 0, 'stub': 1}\n",
      "\n",
      "Сколько тебе лет? -> вто-рого года я,\n",
      "{'requests': 3, 'byscript': 1, 'bygenerative': 1, 'stub': 1}\n",
      "\n",
      "Ты человек? -> Чиво?\n",
      "{'requests': 4, 'byscript': 1, 'bygenerative': 1, 'stub': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
